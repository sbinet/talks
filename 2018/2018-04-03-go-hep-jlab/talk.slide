# Go-HEP: Providing robust concurrent software for HEP
Computing Round Table @JLAB, 2018-04-03

Sebastien Binet
CNRS/IN2P3/LPC-Clermont
https://github.com/sbinet
@0xbins
sebastien.binet@clermont.in2p3.fr

## Software in HEP

  - **50's-90's**: `FORTRAN77`
  - **90's-...**: `C++`
  - **00's-...**: `Python`

Software in HEP is mostly `C++/Python` (with "pockets" of `Java` and `Fortran`.)

.image _figs/data-flux-summary-all.png 300 _

## Software in HEP is painful

**Painful** to develop:

  - deep and complex software stacks
  - huge dependencies issues (install, support)
  - compilation time
  - complex deployment of multi-GB stacks (shared libraries, configuration, DBs, ...)
  - `C++` is a complex language to learn, read, write and maintain
  - unpleasant edit-compile-run development cycle

## Software in HEP is painful

**Painful** to use:

  - overly complicated Object Oriented systems
  - overly complicated inheritance hierarchies
  - overly complicated meta-template programming
  - installation of dependencies
  - granularity of dependencies
  - no simple, nor standard, way to handle dependencies across OSes, experiments, groups, ...
  - documentation

End-users tend to prefer `Python` because of its nicer development cycle, despite its runtime performances (or lack thereof.)

## Software in HEP: optimization and performances

Software is painful and does not perform well:

  - most of our stack is not optimized (OO anti-patterns, code-bloat from `C++` templates)
  - memory leaks, slow to initialize (loading `.so/.dll`), slow to run
  - resources hungry to run and develop (`CPU`, `VMem`, people)
  - most of our stack has to be re-written: support of multi-cores machine, parallelism/concurrency

**Parallelism** and **concurrency** need to be exposed and leveraged, but the language (`C++14`, `C++17`, ...) is **ill** **equiped** for these tasks.

And `C++` is not well adapted for large, distributed development teams (of varying programming skills.)

Time for something new?

## Are those our only options ?

.image _figs/funfast-nogo.svg 500 _

## Enter... Go

## What is Go ?

.play _code/hello.go

	$ go run hello.go
	Hello from Go

A nice language with a nice mascot.

.image _figs/golang-logo.png 200 400

## History

  - Project starts at Google in 2007 (by Griesemer, Pike, Thompson)
  - Open source release in November 2009
  - More than 1000 contributors have joined the project
  - Version 1.0 release in March 2012
  - Version 1.1 release in May 2013
  - Version 1.2 release in December 2013
  - _[...]_
  - Version 1.7 release in August 2016
  - Version 1.8 release in February 2017
  - Version 1.9 release in August 2017
  - Version 1.10 release in February 2018

.link https://golang.org

## Elements of Go

  - Russ Cox, Robert Griesemer, Ian Lance Taylor, Rob Pike, Ken Thompson

  - **Concurrent**, **garbage-collected**
  - An Open-source general progamming language (BSD-3)
  - feel of a **dynamic** **language**: limited verbosity thanks to the _type_ _inference_ _system_, map, slices
  - safety of a **static** **type** **system**
  - compiled down to machine language (so it is fast, goal is ~10% of C)
  - **object-oriented** but w/o classes, **builtin** **reflection**
  - first-class functions with **closures**
  - implicitly satisfied **interfaces**

Available on all major platforms (`Linux`, `Windows`, `macOS`, `Android`, `iOS`, ...) and for many architectures (`amd64`, `arm`, `arm64`, `i386`, `s390x`, `mips64`, ...)

## Concurrency

.image _figs/busy.jpg

Go's concurrency primitives - **goroutines** and **channels** - derive from Hoare's Communicating Sequential Processes (CSP.)

Goroutines are like threads: they share memory.

But cheaper:

  - Smaller, segmented stacks.
  - Many goroutines per operating system thread

## Goroutines

  - The _go_ statement launches a function call as a goroutine

	go f()
	go f(x, y, ...)

  - A goroutine runs concurrently (but not necessarily in parallel)
  - A goroutine has its own (growable/shrinkable) stack

## Concurrency: basic examples

## A boring function

We need an example to show the interesting properties of the concurrency primitives.
To avoid distraction, we make it a boring example.

.play _code/boring.go /START/,/STOP/

## Slightly less boring

Make the intervals between messages unpredictable (still under a second).

.code _code/lessboring.go /START/,/STOP/

## Running it

The boring function runs on forever, like a boring party guest.

.play _code/lessboring.go /^func.main/,$

## Ignoring it

The `go` statement runs the function as usual, but doesn't make the caller wait.

It launches a goroutine.

The functionality is analogous to the `&` on the end of a shell command.

.play _code/goboring.go 1,/^}/

## Ignoring it a little less

When `main` returns, the program exits and takes the boring function down with it.

We can hang around a little, and on the way show that both main and the launched goroutine are running.

.play _code/waitgoboring.go /func.main/,/^}/

## Goroutines

What is a goroutine? It's an independently executing function, launched by a go statement.

It has its own call stack, which grows and shrinks as required.

It's very cheap. It's practical to have thousands, even hundreds of thousands of goroutines.

It's not a thread.

There might be only one thread in a program with thousands of goroutines.

Instead, goroutines are multiplexed dynamically onto threads as needed to keep all the goroutines running.

But if you think of it as a very cheap thread, you won't be far off.

## Communication

Our boring examples cheated: the main function couldn't see the output from the other goroutine.

It was just printed to the screen, where we pretended we saw a conversation.

Real conversations require communication.

## Channels

A channel in Go provides a connection between two goroutines, allowing them to communicate.

.code _code/helpers.go /START1/,/STOP1/
.code _code/helpers.go /START2/,/STOP2/
.code _code/helpers.go /START3/,/STOP3/

## Using channels

A channel connects the main and boring goroutines so they can communicate.

.play _code/changoboring.go /START1/,/STOP1/
.code _code/changoboring.go /START2/,/STOP2/

## Synchronization

When the main function executes <–c, it will wait for a value to be sent.

Similarly, when the boring function executes c <– value, it waits for a receiver to be ready.

A sender and receiver must both be ready to play their part in the communication. Otherwise we wait until they are.

Thus channels both communicate and synchronize.

## Daisy-chain

.play _code/daisy.go /func/,$

## Chinese whispers, gopher style

.image _figs/gophereartrumpet.jpg

## The Go approach

_"Don't communicate by sharing memory, share memory by communicating."_

Goroutines and channels make it easy to express complex operations dealing with:

  - multiple inputs
  - multiple outputs
  - timeouts
  - failure

And they're fun to use.

## More on Go

.link https://tour.golang.org
.link https://golang.org/doc/effective_go.html
.link https://blog.golang.org
.link https://talks.golang.org

About concurrency:

.link https://talks.golang.org/2012/waza.slide
.link https://talks.golang.org/2013/advconc.slide

About s/w engineering with Go:

.link https://talks.golang.org/2012/splash.article

## Go for HEP

What can [Go](https://golang.org) bring to science and HEP?

  - a **simple** language anybody can learn in days, proficient in a couple of months
  - **standard** tool to handle **dependencies** (across OSes, architectures)
  - **fast** edit-compile-run development cycle
  - **simple** deployment (on clusters, laptops, ...), **easiest** **cross-compilation** system to date
  - fast at runtime, builtin tools for profiling (CPU, mem, tracing)
  - support for **concurrency** programming and multi-core machines
  - no magic, no voodoo, **reduce** disconnect b/w HEP sw experts and HEP users
  - **easy** code sharing: between packages, between experiments, between scientists
  - easier **reproducibility** and cross-check tests
  - **refactoring** tools & linters

## Go for HEP: challenges

`$EXPERIMENT` is taking data:

  - one can't really migrate (monolithic) MLoC software stacks while taking data, neither during a long shutdown

**Convincing** physicists:

  - need to prove `Go` is useful, pleasant to use and viable
  - need to prove one can carry an analysis in `Go`, faster than by other means
  - provide 1 or 2 "poster child" applications

**Need** to implement:

  - histograms, PDFs, plotting, fits, BLAS/LAPACK, I/O
  - (some level of) inter-operability with `C++/ROOT`

=> [go-hep.org](https://go-hep.org) is the beginning of such an endeavour

## Go-HEP

2 work areas to demonstrate `Go`'s applicability for HEP use cases have been identified:

  - `DAQ`, monitoring, control command
  - detector fast simulation toolkit (a la [Delphes](https://cp3.irmp.ucl.ac.be/projects/delphes))

## Go-DAQ

`DAQ`, monitoring and control command need `I/O`, network libraries and performances.
`Go` is a great fit for these and has concurrency building blocks to top it all.

These have been already tested at LPC and is gaining traction outside:

  - LSST@LPC: control command + monitoring of the LPC testbench for LSST ([code](https://github.com/go-lsst/fcs-lpc-motor-ctl))
  - AVIRM@LPC: DAQ + monitoring for a medical application ([code](https://gitlab.in2p3.fr/avirm/analysis-go))
  - SoLid@Oxford: DAQ ([talk@IEEE (PDF)](https://users.physics.ox.ac.uk/~ryder/talks/ryder-soliddaq-ieeenss-01Nov16.pdf))
  - SoLid@LPC: sensor monitoring application for RaspBerry-3 ([code](https://github.com/sbinet-solid/tcp-srv))

Started to gather DAQ-HEP oriented packages under the [go-daq](https://github.com/go-daq) organization.

## Go-DAQ (LSST)

.image _figs/fcs-lsst.png 550 _

## Go-DAQ (AVIRM)

.image _figs/avirm-dpga-1.png 500 _

## Go-HEP - fast-simulation

## fads

`fads` is a "FAst Detector Simulation" toolkit.

  - morally a translation of [C++-Delphes](https://cp3.irmp.ucl.ac.be/projects/delphes) into Go
  - uses [hep/fwk](https://go-hep.org/x/hep/fwk) to expose, manage and harness concurrency into the usual `HEP` event loop (`initialize` | `process-events` | `finalize`)
  - uses [hep/hbook](https://go-hep.org/x/hep/hbook) for histogramming, [hep/hepmc](htpps://go-hep.org/x/hep/hepmc) for `HepMC` input/output

Code is on github (BSD-3):

.link https://go-hep.org/x/hep/fwk
.link https://go-hep.org/x/hep/fads

Documentation is served by [godoc.org](https://godoc.org):

.link https://godoc.org/go-hep.org/x/hep/fwk
.link https://godoc.org/go-hep.org/x/hep/fads

## go-hep/fads - Installation

As easy as:

	$ export GOPATH=$HOME/dev/gocode
	$ export PATH=$GOPATH/bin:$PATH

	$ go get go-hep.org/x/hep/fads/...

Yes, with the ellipsis at the end, to also install sub-packages.

  - `go` `get` will recursively download and install all the packages that [hep/fads](https://go-hep.org/x/hep/fads) depends on
  - then actually build and install [hep/fads](https://go-hep.org/x/hep/fads)
  - no `Makefile`, no `CMakeList.txt` involved in the process

## go-hep/fwk - Concurrency

[fwk](https://go-hep.org/x/hep/fwk) enables:

  - event-level concurrency
  - tasks-level concurrency

[fwk](https://go-hep.org/x/hep/fwk) relies on [Go](https://golang.org)'s runtime to properly schedule _goroutines_.

For sub-task concurrency, users are by construction required to use [Go](https://golang.org)'s constructs (_goroutines_ and _channels_) so everything is consistent **and** the _runtime_ has the **complete** **picture**.

  - **Note:** [Go](https://golang.org)'s runtime isn't yet _NUMA-aware_. A proposal is in the [works](https://docs.google.com/document/d/1d3iI2QWURgDIsSR6G2275vMeQ_X7w-qxM2Vp7iGwwuM/pub).

## go-hep/fads - real world use case

  - translated [C++-Delphes](https://cp3.irmp.ucl.ac.be/projects/delphes)' ATLAS data-card into Go
  - [go-hep/fads-app](https://github.com/go-hep/hep/blob/master/fads/cmd/fads-app/main.go)
  - installation:

	$ go get go-hep.org/x/hep/fads/cmd/fads-app
	$ fads-app -help
	Usage: fads-app [options] <hepmc-input-file>

	ex:
	 $ fads-app -l=INFO -evtmax=-1 ./testdata/hepmc.data

	options:
	  -cpu-prof=false: enable CPU profiling
	  -evtmax=-1: number of events to process
	  -l="INFO": log level (DEBUG|INFO|WARN|ERROR)
	  -nprocs=0: number of concurrent events to process

## go-hep/fads - components

  - a `HepMC` converter
  - particle propagator
  - calorimeter simulator
  - energy rescaler, momentum smearer
  - isolation
  - b-tagging, tau-tagging
  - jet-finder (reimplementation of FastJet in Go: [go-hep/fastjet](https://go-hep.org/x/hep/fastjet))
  - histogram service (from [go-hep/fwk](https://go-hep.org/x/hep/fwk))

Caveats:

  - jet clustering limited to N^3 (slowest and dumbest scheme of `C++-FastJet`)

## 

.image _figs/fads-dflow.png 600 600

## Results - testbenches

  - Linux: Intel(R) Xeon(R) CPU X5650  @ 2.67GHz, 24 cores, 56Gb RAM
  - Linux: Intel(R) Xeon(R) CPU E5-4620 0 @ 2.20GHz, 64 cores, 128Gb RAM

  - Delphes, 3.0.12, gcc4.8
  - fads, Go-1.9

	$> time delphes ./input.hepmc
	$> time fads-app ./input.hepmc

## 

.image _figs/linux-64-cores-rss.png 600 _

## 

.image _figs/linux-64-cores-hz.png 600 _

## fads: Results & Conclusions

  - good RSS scaling
  - good CPU scaling

  - bit-by-bit matching physics results wrt `Delphes` (up to calorimetry)
  - no need to merge output files, less chaotic I/O, less I/O wait

## Rivet & fads

## Rivet

The [Rivet](http://rivet.hepforge.org/) toolkit (Robust Independent Validation of Experiment and Theory) is a system for validation of Monte Carlo event generators. It provides a large (and ever growing) set of experimental analyses useful for MC generator development, validation, and tuning, as well as a convenient infrastructure for adding your own analyses.

	$> repeat 10 'time rivet --analysis=MC_GENERIC -q  ./Z-hadronic-LEP.hepmc > /dev/null'
	real=13.32 user=12.97 sys=0.33 CPU=99% MaxRSS=26292
	real=13.31 user=12.93 sys=0.37 CPU=99% MaxRSS=26356
	real=13.29 user=12.93 sys=0.35 CPU=99% MaxRSS=26440
	real=13.31 user=12.95 sys=0.35 CPU=99% MaxRSS=26356
	real=13.29 user=13.01 sys=0.27 CPU=99% MaxRSS=26280
	real=13.31 user=12.97 sys=0.32 CPU=99% MaxRSS=26328
	real=13.35 user=12.93 sys=0.41 CPU=99% MaxRSS=26276
	real=13.30 user=12.96 sys=0.33 CPU=99% MaxRSS=26624
	real=13.30 user=12.93 sys=0.36 CPU=99% MaxRSS=26440
	real=13.35 user=12.98 sys=0.36 CPU=99% MaxRSS=26484

## fads-rivet-mc-generic

Reimplementation on top of [go-hep/fwk+fads](https://godoc.org/go-hep.org/x/hep/fwk) of the `MC_GENERIC` analysis.

Bit-to-bit identical results.

	$> go get go-hep.org/x/hep/fads/cmd/fads-rivet-mc-generic

	$> repeat 10 'time fads-rivet-mc-generic -nprocs=1 ./Z-hadronic-LEP.hepmc > /dev/null'
	real=6.04 user=5.66 sys=0.12 CPU= 95% MaxRSS=23384
	real=5.70 user=5.62 sys=0.09 CPU=100% MaxRSS=21128
	real=5.71 user=5.58 sys=0.11 CPU= 99% MaxRSS=22208
	real=5.68 user=5.60 sys=0.08 CPU=100% MaxRSS=23156
	real=5.71 user=5.63 sys=0.08 CPU=100% MaxRSS=20672
	real=5.78 user=5.62 sys=0.09 CPU= 98% MaxRSS=22328
	real=5.67 user=5.62 sys=0.05 CPU=100% MaxRSS=20968
	real=5.68 user=5.57 sys=0.07 CPU= 99% MaxRSS=23748
	real=5.70 user=5.60 sys=0.10 CPU=100% MaxRSS=21360
	real=5.72 user=5.65 sys=0.07 CPU=100% MaxRSS=22764

## ROOT I/O

[Go-HEP](https://go-hep.org) provides some amount of interoperability with `ROOT-{5,6}` via [go-hep.org/x/hep/rootio](https://go-hep.org/x/hep/rootio), a pure-Go package (no `C++`, no `ROOT`, no `PyROOT`, just [Go](https://golang.org)) that:

  - decodes and understands the structure of `TFiles`, `TKeys`, `TDirectory` and `TStreamerInfos`,
  - decodes, deserializes `TH1x`, `TH2x`, `TLeaf`, `TBranch` and `TTrees`

For the moment, only the "**I**" part of ROOT I/O has been implemented (**O** is starting), but it's already quite useful:

  - `cmd/root-ls`
  - `cmd/root-dump`, `cmd/root-diff`, `cmd/root-print`, `cmd/root-gen-datareader`
  - `cmd/root2csv`
  - `cmd/root2npy`, `cmd/root2yoda`
  - `cmd/root-srv`

## root-srv (served by AppEngine)

.image _figs/root-srv-screenshot.jpg 550 _

## ROOT I/O

	f, err := rootio.Open("my-file.root")
	obj, err := f.Get("my-tree")
	tree := obj.(rootio.Tree)

	type Data struct {
		I64    int64       `rootio:"Int64"`
		F64    float64     `rootio:"Float64"`
		Str    string      `rootio:"Str"`
		ArrF64 [10]float64 `rootio:"ArrayFloat64"`
		N      int32       `rootio:"N"`
		SliF64 []float64   `rootio:"SliceFloat64"`
	}

	var data Data
	sc, err := rootio.NewScanner(tree, &data)

	for sc.Next() {
		err := sc.Scan()
		if err != nil {
			log.Fatal(err)
		}
		fmt.Printf("entry[%d]: %+v\n", sc.Entry(), data)
	}

## ROOT I/O features

  - read flat TTrees with C/C++ builtins, static/dynamic arrays of C/C++ builtins
  - read "event" TTrees with user defined classes containing: `std::vector<T>` (where `T` is a C/C++ builtin or a `std::string / TString`), another user defined class, `std::string` or `TString`, static/dynamic arrays of C/C++ builtins and, of course C/C++ builtins

	struct P3 { int32_t Px; double  Py; int32_t Pz; };

	struct Event {
	  int16_t  I16;  int32_t  I32; int64_t  I64; uint32_t U32;
	  float    F32;  double   F64;
	  TString  TStr; std::string StdStr;
	  P3       P3;
	  int16_t  ArrayI16[ARRAYSZ]; int32_t  ArrayI32[ARRAYSZ];
	  double   ArrayF64[ARRAYSZ];
	  int32_t  N;
	  int16_t  *SliceI16;  //[N]
	  int32_t  *SliceI32;  //[N]
	  double   *SliceF64;  //[N]
	  std::vector<int64_t> StlVecI64; std::vector<std::string> StlVecStr;
	};

## ROOT I/O performances

  - Input files:

	$> ll *root
	-rw-r--r-- 1 binet binet 686M Aug 16 11:00 f64s-default-compress.root
	-rw-r--r-- 1 binet binet 764M Aug 16 15:39 f64s-no-compress.root

	$> root-ls -t f64s-no-compress.root
	=== [f64s-no-compress.root] ===
	version: 61002
	TTree       tree          tree    (entries=1000000)
	  Scalar_0  "Scalar_0/D"  TBranch
	  Scalar_1  "Scalar_1/D"  TBranch
	  Scalar_2  "Scalar_2/D"  TBranch
	  [...]
	  Scalar_98 "Scalar_98/D" TBranch
	  Scalar_99 "Scalar_99/D" TBranch

## ROOT - C++

	auto f = TFile::Open(argv[1], "read");
	auto t = (TTree*)f->Get("tree");

	const Long_t BRANCHES= 100;

	Double_t v[BRANCHES] = {0};

	for (int i = 0; i < BRANCHES; i++) {
		auto n = TString::Format("Scalar_%d", i);
		t->SetBranchAddress(n, &v[i]);
	}

	Long_t entries = t->GetEntries();
	Double_t sum = 0;
	for ( Long_t i = 0; i < entries; i++ ) {
		t->GetEntry(i);
		sum += v[0];
	}

	std::cout << "sum= " << sum << "\n";

## Go-HEP/rootio

	f, err := rootio.Open(flag.Arg(0))
	obj, err := f.Get("tree")
	t := obj.(rootio.Tree)

	var vs [100]float64
	var svars []rootio.ScanVar
	for i := range vs {
		svars = append(svars, rootio.ScanVar{
			Name:  fmt.Sprintf("Scalar_%d", i),
			Value: &vs[i],
		})
	}

	sum := 0.0
	scan, err := rootio.NewScannerVars(t, svars...)
	for scan.Next() {
		err = scan.Scan()
		if err != nil {
			log.Fatal(err)
		}
		sum += vs[0]
	}

	fmt.Printf("sum= %v\n", sum)

## Results -- No Compression

	$> time ./cxx-read-data
	$> time ./go-read-data

	=== ROOT === (VMem=517Mb)
	real=6.70 user=6.18 sys=0.51 CPU= 99% MaxRSS=258296
	real=6.84 user=6.32 sys=0.51 CPU= 99% MaxRSS=257748
	real=6.82 user=6.29 sys=0.52 CPU= 99% MaxRSS=258348
	real=6.66 user=6.13 sys=0.53 CPU=100% MaxRSS=258440

	=== go-hep/rootio === (VMem=43Mb)
	real=12.94 user=12.39 sys=0.56 CPU=100% MaxRSS=42028
	real=12.93 user=12.37 sys=0.56 CPU=100% MaxRSS=42072
	real=12.96 user=12.38 sys=0.58 CPU=100% MaxRSS=41984
	real=12.94 user=12.36 sys=0.57 CPU=100% MaxRSS=42048

## Results -- with default compression

	=== ROOT === (VMem=529Mb)
	real=20.61 user=11.86 sys=0.63 CPU=60% MaxRSS=292640
	real=12.56 user=11.54 sys=0.51 CPU=96% MaxRSS=290124
	real=12.04 user=11.50 sys=0.52 CPU=99% MaxRSS=290444
	real=12.05 user=11.54 sys=0.50 CPU=99% MaxRSS=290324

	=== go-hep/rootio === (VMem=83Mb)
	real=36.43 user=35.20 sys=0.69 CPU= 98% MaxRSS=81196
	real=35.75 user=35.15 sys=0.63 CPU=100% MaxRSS=81644
	real=35.76 user=35.10 sys=0.69 CPU=100% MaxRSS=81856
	real=35.70 user=35.18 sys=0.54 CPU=100% MaxRSS=81944

**Only** ~2 times slower, w/o any optimization wrt baskets buffering, TTreeCache, ...
No concurrency (yet.)

Of course, `go-hep/rootio` provides less features than ROOT, isn't as battle-tested and is probably full of bugs.
But it's in the same order of magnitude, performance-wise.

## Conclusions - Go

[Go](https://golang.org) improves on `C/C++/Java/...` and addresses `C/C++` and `python` deficiencies:

  - code distribution, code installation (static binaries)
  - compilation/development speed, unit tests
  - runtime speed
  - simple language (to learn, teach and master)
  - simple cross compilation:
    $> GOARCH=arm64 GOOS=linux   go build -o foo-linux-arm64.exe
    $> GOARCH=amd64 GOOS=windows go build -o foo-windows-64b.exe

and:

  - serviceable standard library ([stdlib doc](https://golang.org/pkg))
  - builtin facilities to tackle concurrency programming

## Conclusions - Go-HEP

[Go-HEP](https://go-hep.org) provides some building blocks that are already competitive with battle-tested C++ programs, both in terms of CPU, memory usage and cores' harnessing.

Further improvements are still necessary in the `ROOT` `I/O` compatibility part:

  - performances
  - features (write capabilities + more read use-cases)

Further improvements in the Jupyter area are also warranted (but that's tackled by the Go data science community at large):

  - MyBinder+Go-HEP: [mybinder](https://mybinder.org/v2/gh/go-hep/binder/master)
  - [Gonum](https://gonum.org): the NumPy+SciPy of Go

[Go-HEP](https://go-hep.org) has also users outside LPC-Clermont:

  - [github.com/decibelcooper/proio](https://github.com/decibelcooper/proio)

## Conclusions

Go is great at writing small and large (concurrent) programs.
Also true for **science-y** programs, even if the amount of libraries can still be improved.

.image _figs/funfast.svg 320 _

Write your next tool/analysis/simulation/software in [Go](https://golang.org/)?

## Go-HEP packages

  - [go-hep.org/x/hep/fads](https://godoc.org/go-hep.org/x/hep/fads): a fast detector simulation toolkit
  - [go-hep.org/x/hep/fastjet](https://godoc.org/go-hep.org/x/hep/fastjet): a jet clustering algorithms package (WIP)
  - [go-hep.org/x/hep/fit](https://godoc.org/go-hep.org/x/hep/fit): a fitting function toolkit (WIP)
  - [go-hep.org/x/hep/fmom](https://godoc.org/go-hep.org/x/hep/fmom): a 4-vectors library
  - [go-hep.org/x/hep/fwk](https://godoc.org/go-hep.org/x/hep/fwk): a concurrency-enabled framework
  - [go-hep.org/x/hep/hbook](https://godoc.org/go-hep.org/x/hep/hbook): histograms and n-tuples (WIP)
  - [go-hep.org/x/hep/hplot](https://godoc.org/go-hep.org/x/hep/hplot): interactive plotting (WIP), SVG, PNG, PDF, LaTeX output
  - [go-hep.org/x/hep/hepmc](https://godoc.org/go-hep.org/x/hep/hepmc): HepMC in pure Go (EDM + I/O)
  - [go-hep.org/x/hep/hepevt](https://godoc.org/go-hep.org/x/hep/hepevt): HEPEVT bindings
  - [go-hep.org/x/hep/heppdt](https://godoc.org/go-hep.org/x/hep/heppdt): HEP particle data table

## Go-HEP packages (cont'd)

  - [go-hep.org/x/hep/lcio](https://godoc.org/go-hep.org/x/hep/lcio): read/write support for LCIO event data model
  - [go-hep.org/x/hep/lhef](https://godoc.org/go-hep.org/x/hep/lhef): Les Houches Event File format
  - [go-hep.org/x/hep/rio](https://godoc.org/go-hep.org/x/hep/rio): go-hep record oriented I/O
  - [go-hep.org/x/hep/rootio](https://godoc.org/go-hep.org/x/hep/rootio): a pure Go package for ROOT I/O (WIP)
  - [go-hep.org/x/hep/sio](https://godoc.org/go-hep.org/x/hep/sio): basic, low-level, serial I/O used by LCIO
  - [go-hep.org/x/hep/slha](https://godoc.org/go-hep.org/x/hep/slha): SUSY Les Houches Accord I/O

## Go-HEP commands

  - [cmd/lhef2hepmc](https://godoc.org/go-hep.org/x/hep/cmd/lhef2hepmc): converts LHEF files to HepMC
  - [cmd/rio2yoda](https://godoc.org/go-hep.org/x/hep/cmd/rio2yoda): converts `rio` files to [YODA](https://yoda.hepforge.org)
  - [cmd/root2npy](https://godoc.org/go-hep.org/x/hep/cmd/root2npy): converts `ROOT` TTrees to `NumPy` `.np(y|z)` files
  - [cmd/root2yoda](https://godoc.org/go-hep.org/x/hep/cmd/root2yoda): converts `ROOT` files to [YODA](https://yoda.hepforge.org)
  - [cmd/yoda2rio](https://godoc.org/go-hep.org/x/hep/cmd/yoda2rio): converts YODA files to `rio`
  - [cmd/root-ls](https://godoc.org/go-hep.org/x/hep/rootio/cmd/root-ls): inspects `ROOT` files' content
  - [cmd/root-dump](https://godoc.org/go-hep.org/x/hep/rootio/cmd/root-dump): dumps `ROOT` files' `TTrees` content
  - [cmd/root-diff](https://godoc.org/go-hep.org/x/hep/rootio/cmd/root-diff): diffs 2 `ROOT` files' `TTrees` content, event by event
  - [cmd/root-print](https://godoc.org/go-hep.org/x/hep/rootio/cmd/root-print): prints to PDF, PNG, ... histograms from a `ROOT` file
  - [cmd/root-srv](https://godoc.org/go-hep.org/x/hep/rootio/cmd/root-srv): web server that displays `ROOT` files' content (plots TH1x, TH2x, TTrees)
  - [PAWgo](https://github.com/go-hep/hep/tree/master/pawgo): a (WIP) reimplementation of `PAW` in Go

## Acknowledgements / resources

.link https://tour.golang.org
.link https://talks.golang.org/2012/splash.slide
.link https://talks.golang.org/2012/goforc.slide
.link https://talks.golang.org/2012/waza.slide
.link https://talks.golang.org/2012/concurrency.slide
.link https://talks.golang.org/2013/advconc.slide
.link https://talks.golang.org/2014/gocon-tokyo.slide
.link https://talks.golang.org/2015/simplicity-is-complicated.slide
.link https://talks.golang.org/2016/applicative.slide
.link https://agenda.infn.it/getFile.py/access?contribId=24&sessionId=3&resId=0&materialId=slides&confId=11680
